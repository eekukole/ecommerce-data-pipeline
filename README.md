# E-Commerce Data Pipeline ğŸš€

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![MySQL](https://img.shields.io/badge/MySQL-8.0-orange.svg)
![Status](https://img.shields.io/badge/Status-In%20Development-yellow.svg)

## ğŸ“Š Project Overview
End-to-end data engineering pipeline for e-commerce analytics, evolving from local development to cloud-native architecture.

## ğŸ¯ Current Status: Phase 1 Complete âœ…

### What's Working:
- âœ… Event generator producing realistic e-commerce data
- âœ… Python data loader (JSON â†’ MySQL)
- âœ… Star schema data warehouse
- âœ… Business analytics queries

### Tech Stack:
- **Language:** Python 3.10+
- **Database:** MySQL 8.0
- **Libraries:** Faker, PyMySQL, python-dotenv
- **Data Model:** Star Schema (Kimball methodology)

## ğŸ“ Project Structure
```
ecommerce-data-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ event_generator.py    # Generates synthetic e-commerce events
â”‚   â””â”€â”€ loader.py              # Loads JSON data into MySQL
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ schema/               # Database table definitions
â”‚   â””â”€â”€ transformations/      # ETL transformation scripts
â”œâ”€â”€ data/
â”‚   â””â”€â”€ events/              # Generated JSON event files
â””â”€â”€ dags/                    # Airflow DAGs (coming soon)
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- MySQL 8.0
- Git

### Setup
```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/ecommerce-data-pipeline.git
cd ecommerce-data-pipeline

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Mac/Linux

# Install dependencies
pip install -r requirements.txt

# Configure database
cp .env.example .env
# Edit .env with your MySQL credentials

# Generate sample data
python src/event_generator.py

# Load into MySQL
python src/loader.py
```

## ğŸ“ˆ Data Warehouse Schema

**Dimensions:**
- `dim_customers` - Customer profiles and segmentation
- `dim_products` - Product catalog
- `dim_date` - Time dimension
- `dim_devices` - Device and browser information

**Facts:**
- `fact_orders` - Purchase transactions
- `fact_page_views` - User browsing behavior

## ğŸ“Š Sample Analytics
```sql
-- Customer Segmentation
SELECT 
    customer_segment,
    COUNT(*) AS customers,
    AVG(total_spent) AS avg_ltv
FROM dim_customers
GROUP BY customer_segment;

-- Daily Revenue Trend
SELECT 
    d.full_date,
    SUM(f.total_amount) AS revenue
FROM fact_orders f
JOIN dim_date d ON f.date_key = d.date_key
GROUP BY d.full_date;
```

## ğŸ¯ Roadmap

- [x] Phase 1: Local pipeline fundamentals
- [ ] Phase 2: Cloud migration (AWS)
- [ ] Phase 3: Airflow orchestration
- [ ] Phase 4: Real-time streaming (Kafka)

## ğŸ“š What I Learned
- Data modeling with star schema design
- ETL pipeline development
- Python-MySQL integration
- Dimensional modeling best practices

## ğŸ¤ Connect
Building in public! Follow my data engineering journey.

---

**Status:** ğŸš§ Active Development | **Next:** Docker + Airflow Setup